{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b840c62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8867041198501873\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"GrammarandProductReviews[modified].csv\")\n",
    "\n",
    "# Preprocess the text\n",
    "df['text'] = df['review'].apply(lambda x: x.lower().split())\n",
    "\n",
    "# Train the CBOW model\n",
    "model = Word2Vec(df['text'], size=100, window=5, min_count=1, sg=1)\n",
    "\n",
    "\n",
    "# Convert the text to numerical vectors using the CBOW model\n",
    "text_vectors = []\n",
    "for i in range(len(df)):\n",
    "    text_vectors.append(np.mean([model.wv[word] for word in df['text'][i]], axis=0))\n",
    "text_vectors = np.array(text_vectors)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_vectors, df['positive_review'], test_size=0.2, random_state=0)\n",
    "\n",
    "# Train multiple classifiers and use a voting ensemble\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3= SVC()\n",
    "ensemble = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2)], voting='hard')\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels on the test set\n",
    "y_pred = ensemble.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef1d70fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy For Voting Ensemble SVM+AadBoost+RF is: 0.901685393258427\n",
      "RMSE Error is: 0.31355160140170396\n",
      "Execution time: 125.90628409385681 seconds\n",
      "Current memory usage is 56.38986778259277 MB; Peak was 78.3046464920044 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from math import sqrt\n",
    "from sklearn.svm import SVC\n",
    "import time\n",
    "import tracemalloc\n",
    "import xgboost as xgb\n",
    "\n",
    "# get the start time\n",
    "st = time.time()\n",
    "tracemalloc.start()\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"GrammarandProductReviews[modified].csv\")\n",
    "\n",
    "# Preprocess the text\n",
    "df['text'] = df['review'].apply(lambda x: x.lower().split())\n",
    "\n",
    "# Train the CBOW model\n",
    "model = Word2Vec(df['text'], size=200, window=20, min_count=1, sg=1)\n",
    "\n",
    "\n",
    "# Convert the text to numerical vectors using the CBOW model\n",
    "text_vectors = []\n",
    "for i in range(len(df)):\n",
    "    text_vectors.append(np.mean([model.wv[word] for word in df['text'][i]], axis=0))\n",
    "text_vectors = np.array(text_vectors)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_vectors, df['positive_review'], test_size=0.2, random_state=0)\n",
    "\n",
    "# Train multiple classifiers and use a voting ensemble\n",
    "LogReg_clf = LogisticRegression()\n",
    "SVC_clf = SVC(probability=True, kernel='rbf')\n",
    "DTree_clf = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier(random_state=1200, criterion='entropy', n_estimators=200)\n",
    "ada = AdaBoostClassifier(n_estimators=200, learning_rate=2.0, algorithm='SAMME')\n",
    "#ada = AdaBoostClassifier()\n",
    "ETree = ExtraTreesClassifier(random_state=42)\n",
    "\n",
    "\n",
    "ensemble = VotingClassifier(estimators=[('svm', SVC_clf), ('AdaBoost', ada), ('RF',rf )], voting='soft')\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels on the test set\n",
    "y_pred = ensemble.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "rms= sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"Accuracy For Voting Ensemble SVM+AadBoost+RF is: \" + str(acc))\n",
    "print(\"RMSE Error is: \" + str(rms))\n",
    "\n",
    "\n",
    "# get the end time\n",
    "et = time.time()\n",
    "\n",
    "# get the execution time\n",
    "elapsed_time = et - st\n",
    "print('Execution time:', elapsed_time, 'seconds')\n",
    "\n",
    "current, peak = tracemalloc.get_traced_memory()\n",
    "# Stop tracemalloc\n",
    "tracemalloc.stop()\n",
    "print(\"Current memory usage is\", current / (1024 * 1024), \"MB; Peak was\", peak / (1024 * 1024), \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "486d542f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for AdaBoost: 0.8703183520599251\n",
      "RMSE: 0.12968164794007492\n",
      "Execution time: 12.649820804595947 seconds\n",
      "Current memory usage is 0.05268383026123047 MB; Peak was 0.6943483352661133 MB\n"
     ]
    }
   ],
   "source": [
    "# Boosting Ensemble (Adaboost classifier)\n",
    "\n",
    "# get the start time\n",
    "st = time.time()\n",
    "tracemalloc.start()\n",
    "\n",
    "clf = AdaBoostClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# evaluate the model's performance using accuracy and RMSE\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy for AdaBoost:\", accuracy)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "# get the end time\n",
    "et = time.time()\n",
    "\n",
    "# get the execution time\n",
    "elapsed_time = et - st\n",
    "print('Execution time:', elapsed_time, 'seconds')\n",
    "\n",
    "current, peak = tracemalloc.get_traced_memory()\n",
    "# Stop tracemalloc\n",
    "tracemalloc.stop()\n",
    "print(\"Current memory usage is\", current / (1024 * 1024), \"MB; Peak was\", peak / (1024 * 1024), \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3af29dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for XGBoost: 0.6427902621722846\n",
      "Execution time: 10.921875476837158 seconds\n",
      "Current memory usage is 0.024506568908691406 MB; Peak was 0.21202564239501953 MB\n"
     ]
    }
   ],
   "source": [
    "# Train XGBoost model\n",
    "# get the start time\n",
    "st = time.time()\n",
    "tracemalloc.start()\n",
    "\n",
    "\n",
    "model = xgb.XGBClassifier(n_estimators=100, learning_rate=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set and calculate accuracy\n",
    "y_pred = model.predict(y_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy for XGBoost:', acc)\n",
    "\n",
    "# get the end time\n",
    "et = time.time()\n",
    "\n",
    "# get the execution time\n",
    "elapsed_time = et - st\n",
    "print('Execution time:', elapsed_time, 'seconds')\n",
    "\n",
    "current, peak = tracemalloc.get_traced_memory()\n",
    "# Stop tracemalloc\n",
    "tracemalloc.stop()\n",
    "#print(f\"Current memory usage is {current / 10**6}MB; Peak was {peak / 10**6}MB\")\n",
    "print(\"Current memory usage is\", current / (1024 * 1024), \"MB; Peak was\", peak / (1024 * 1024), \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebe67ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa4fd1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a81095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addaf386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eee29d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.869479524612051\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "LogReg_clf = LogisticRegression(max_iter=1000)\n",
    "logreg_bagging_model = BaggingClassifier(base_estimator=LogReg_clf, n_estimators=50)\n",
    "\n",
    "#dtree_bagging_model = BaggingClassifier(base_estimator=DTree_clf, n_estimators=50)\n",
    "#random_forest = RandomForestClassifier(n_estimators=100)\n",
    "#extra_trees = ExtraTreesClassifier(n_estimators=100)\n",
    "\n",
    "def bagging_ensemble(model):\n",
    "    k_folds = KFold(n_splits=20)\n",
    "    results = cross_val_score(model, X_train, y_train, cv=k_folds)\n",
    "    print(results.mean())\n",
    "\n",
    "bagging_ensemble(logreg_bagging_model)\n",
    "#bagging_ensemble(dtree_bagging_model)\n",
    "#bagging_ensemble(random_forest)\n",
    "#bagging_ensemble(extra_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26ad3c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, log_loss, mean_squared_error,recall_score,precision_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72cadc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8703183520599251\n",
      "RMSE: 0.12968164794007492\n"
     ]
    }
   ],
   "source": [
    "# train the Adaboost classifier\n",
    "clf = AdaBoostClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# evaluate the model's performance using accuracy and RMSE\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4004fb2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3aef9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8787453183520599\n"
     ]
    }
   ],
   "source": [
    "#Skip-Gram\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('GrammarandProductReviews[modified].csv')\n",
    "\n",
    "# Preprocess the data by tokenizing the text and creating a list of words\n",
    "df['text'] = df['review'].apply(lambda x: x.split())\n",
    "\n",
    "# Train a skip-gram word2vec model\n",
    "model = Word2Vec(df['text'], size=100, window=5, min_count=1, sg=1)\n",
    "\n",
    "# Extract features from the text using the skip-gram model\n",
    "text_vectors = []\n",
    "for i in range(len(df)):\n",
    "    text_vectors.append(np.mean([model.wv[word] for word in df['text'][i]], axis=0))\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_vectors, df['positive_review'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the classifiers\n",
    "clf1 = LogisticRegression()\n",
    "clf2 = GaussianNB()\n",
    "clf3 = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Create the voting ensemble classifier\n",
    "ensemble = VotingClassifier(estimators=[('lr', clf1), ('gnb', clf3)], voting='hard')\n",
    "\n",
    "# Train the ensemble classifier\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = ensemble.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: ', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd08177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, log_loss, mean_squared_error,recall_score,precision_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9492deca",
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg_clf = LogisticRegression()\n",
    "SVC_clf = SVC()\n",
    "DTree_clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97e21b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8872751099827092\n"
     ]
    }
   ],
   "source": [
    "#Bagging Ensemble Method\n",
    "#logreg_bagging_model = BaggingClassifier(base_estimator=LogReg_clf, n_estimators=50)\n",
    "dtree_bagging_model = BaggingClassifier(base_estimator=DTree_clf, n_estimators=50)\n",
    "#random_forest = RandomForestClassifier(n_estimators=100)\n",
    "#extra_trees = ExtraTreesClassifier(n_estimators=100)\n",
    "\n",
    "def bagging_ensemble(model):\n",
    "    k_folds = KFold(n_splits=20)\n",
    "    results = cross_val_score(model, X_train, y_train, cv=k_folds)\n",
    "    print(results.mean())\n",
    "\n",
    "#bagging_ensemble(logreg_bagging_model)\n",
    "bagging_ensemble(dtree_bagging_model)\n",
    "#bagging_ensemble(random_forest)\n",
    "#bagging_ensemble(extra_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fa1b285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8506554307116105\n",
      "RMSE: 0.14934456928838952\n"
     ]
    }
   ],
   "source": [
    "# train the Adaboost classifier\n",
    "clf = AdaBoostClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# evaluate the model's performance using accuracy and RMSE\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"RMSE:\", rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
