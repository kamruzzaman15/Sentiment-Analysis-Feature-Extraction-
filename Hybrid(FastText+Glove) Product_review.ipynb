{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6def0bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.models import FastText\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import gensim.downloader as api\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB,BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from math import sqrt\n",
    "from sklearn.svm import SVC\n",
    "import time\n",
    "import tracemalloc\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('GrammarandProductReviews[modified].csv')\n",
    "\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(df['review'], df['positive_review'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Load the FastText and Glove pre-trained models\n",
    "ft_model = api.load('fasttext-wiki-news-subwords-300')\n",
    "glove_model = api.load(\"glove-wiki-gigaword-300\")\n",
    "\n",
    "# Define a function to extract hybrid features\n",
    "def hybrid_features(text):\n",
    "    ft_feature = np.mean([ft_model.get_vector(word) for word in text if word.strip()], axis=0)\n",
    "    glove_feature = np.mean([glove_model.get_vector(word) for word in text if word.strip()], axis=0)\n",
    "    return np.concatenate((ft_feature, glove_feature))\n",
    "\n",
    "\n",
    "# Extract features for train and test sets\n",
    "train_features = np.array([hybrid_features(text) for text in train_data])\n",
    "test_features = np.array([hybrid_features(text) for text in test_data])\n",
    "\n",
    "LogReg_clf = LogisticRegression(max_iter=1000)\n",
    "SVC_clf = SVC(probability=True, kernel='rbf')\n",
    "NV=MultinomialNB()\n",
    "DTree_clf = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier(random_state=1200, criterion='entropy', n_estimators=200)\n",
    "ada = AdaBoostClassifier(n_estimators=200, learning_rate=1.0, algorithm='SAMME')\n",
    "#ada = AdaBoostClassifier()\n",
    "ETree = ExtraTreesClassifier(random_state=42)\n",
    "\n",
    "#Voting Ensemble Method\n",
    "voting_clf = VotingClassifier(estimators=[('svm', SVC_clf), ('AdaBoost', ada), ('RF',rf )], voting='soft')\n",
    "voting_clf.fit(train_features, train_labels)\n",
    "preds = voting_clf.predict(test_features)\n",
    "\n",
    "acc = accuracy_score(test_labels, preds)\n",
    "rms= sqrt(mean_squared_error(test_labels, preds))\n",
    "\n",
    "\n",
    "print(\"Accuracy For Voting Ensemble SVM+AadBoost+RF is: \" + str(acc))\n",
    "print(\"RMSE Error is: \" + str(rms))\n",
    "\n",
    "\n",
    "# Train a BaggingClassifier using Logistic Regression as the base estimator\n",
    "clf = BaggingClassifier(base_estimator=LogReg_clf, n_estimators=100, random_state=42)\n",
    "clf.fit(train_features, train_labels)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = clf.predict(test_features)\n",
    "\n",
    "# Evaluate the model using accuracy\n",
    "acc = accuracy_score(test_labels, predictions)\n",
    "rms= sqrt(mean_squared_error(test_labels, predictions))\n",
    "print('Accuracy for Bagged LR:', acc)\n",
    "print(\"RMSE Error is: \" + str(rms))\n",
    "\n",
    "\n",
    "# Train a BaggingClassifier using Logistic Regression as the base estimator\n",
    "clf = BaggingClassifier(base_estimator=rf, n_estimators=100, random_state=42)\n",
    "clf.fit(train_features, train_labels)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = clf.predict(test_features)\n",
    "\n",
    "# Evaluate the model using accuracy\n",
    "acc = accuracy_score(test_labels, predictions)\n",
    "rms= sqrt(mean_squared_error(test_labels, predictions))\n",
    "print('Accuracy for Bagged RF:', acc)\n",
    "print(\"RMSE Error is: \" + str(rms))\n",
    "\n",
    "# Train a BaggingClassifier using DTree as the base estimator\n",
    "clf = BaggingClassifier(base_estimator=DTree_clf, n_estimators=100, random_state=42)\n",
    "clf.fit(train_features, train_labels)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = clf.predict(test_features)\n",
    "\n",
    "# Evaluate the model using accuracy\n",
    "acc = accuracy_score(test_labels, predictions)\n",
    "rms= sqrt(mean_squared_error(test_labels, predictions))\n",
    "print('Accuracy for Bagged DT:', acc)\n",
    "print(\"RMSE Error is: \" + str(rms))\n",
    "\n",
    "clf = xgb.XGBClassifier(n_estimators=70, learning_rate=0.9)\n",
    "clf.fit(train_features, train_labels)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = clf.predict(test_features)\n",
    "\n",
    "# Evaluate the model using accuracy\n",
    "acc = accuracy_score(test_labels, predictions)\n",
    "rms= sqrt(mean_squared_error(test_labels, predictions))\n",
    "print('Accuracy for Xboost:', acc)\n",
    "print(\"RMSE Error is: \" + str(rms))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
